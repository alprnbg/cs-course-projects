{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1><center>CMPE 462 - Project 2<br>Implementing an SVM Classifier<br>Due: May 18, 2020, 23:59</center></h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* **Student ID1:2016400198**\n",
    "* **Student ID2:2016400126**\n",
    "* **Student ID3:2018400279**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overview\n",
    "\n",
    "In this project, you are going to implement SVM. For this purpose, a data set (data.mat) is given to you. You can load the mat dataset into Python using the function `loadmat` in `Scipy.io`. When you load the data, you will obtain a dictionary object, where `X` stores the data matrix and `Y` stores the labels. You can use the first 150 samples for training and the rest for testing. In this project, you will use the software package [`LIBSVM`](http://www.csie.ntu.edu.tw/~cjlin/libsvm/) to implement SVM. Note that `LIBSVM` has a [`Python interface`](https://github.com/cjlin1/libsvm/tree/master/python), so you can call the SVM functions in Python. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 1 - 30 pts\n",
    "\n",
    "Train a hard margin linear SVM and report both train and test classification accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy.io\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from libsvm import svmutil as svm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mat = scipy.io.loadmat('data.mat')\n",
    "\n",
    "y_train = mat['Y'][:150,:].squeeze()\n",
    "X_train = mat['X'][:150,:]\n",
    "\n",
    "y_test = mat['Y'][150:,:].squeeze()\n",
    "X_test = mat['X'][150:,:]\n",
    "options = '-c 1e10'  # Very high C value imitates hard margin SVM\n",
    "# Training Model\n",
    "model = svm.svm_train(y_train, X_train, options)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svm.svm_predict(y_test, X_test, model)\n",
    "svm.svm_predict(y_train, X_train, model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 2 - 40 pts\n",
    "\n",
    "Train soft margin SVM for different values of the parameter $C$, and with different kernel functions. Systematically report your results. For instance, report the performances of different kernels for a fixed $C$, then report the performance for different $C$ values for a fixed kernel, and so on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "c_values = ['0.1','1','2','5','10']\n",
    "t_values = {0:\"Linear\", 1:\"Polynomial\", 2:\"RBS\", 3:\"Sigmoid\"}\n",
    "\n",
    "for c in c_values:\n",
    "    for t in t_values.keys():\n",
    "        options = \"-t {} -c {}\".format(t, c)\n",
    "        model = svm.svm_train(y_train, X_train, options)\n",
    "        print(\"Kernel:\",t_values[t], '-- C =', c)\n",
    "        pred_values, (acc,mse,scc), pred_values = svm.svm_predict(y_test, X_test, model)\n",
    "        print('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 3 - 15 pts\n",
    "\n",
    "Please report how the number of support vectors changes as the value of $C$ increases (while all other parameters remain the same). Discuss whether your observations match the theory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_of_s_vectors = []\n",
    "c_values = ['0.1','1','3','6','13','29','51','83','1e+2','231','1e+3',]\n",
    "for c in c_values:\n",
    "    options = \"-t 3 -c {}\".format(c)\n",
    "    model = svm.svm_train(y_train, X_train, options)\n",
    "    n_of_s_vectors.append(len(model.get_SV()))\n",
    "\n",
    "c_values = list(map(float,c_values))\n",
    "plt.plot(c_values,n_of_s_vectors)\n",
    "plt.xlabel(\"penalty constant\")\n",
    "plt.ylabel(\"number of support vectors\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 4 - 15 pts\n",
    "\n",
    "Please investigate the changes in the hyperplane when you remove one of the support vectors, vs., one data point that is not a support vector."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# main training model\n",
    "options = \"-t 0 -c 0.1\"\n",
    "main_model = svm.svm_train(y_train, X_train, options)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "index = main_model.get_sv_indices()[0]-1\n",
    "\n",
    "sv_removed_x_train = np.concatenate([X_train[:index],X_train[index+1:]])\n",
    "sv_removed_y_train = np.concatenate([y_train[:index],y_train[index+1:]])\n",
    "\n",
    "model_sv_removed = svm.svm_train(sv_removed_y_train, sv_removed_x_train, options)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# one non support vector removed model\n",
    "\n",
    "index = -1\n",
    "for i in range(len(X_train)):\n",
    "    data = X_train[i,:]\n",
    "    for sv in main_model.get_SV():\n",
    "        if (list(data) != list(sv.values())[:-1]):\n",
    "            index = i\n",
    "            break\n",
    "    if index != -1:\n",
    "        break\n",
    "\n",
    "non_sv_removed_x_train = np.concatenate([X_train[:index],X_train[index+1:]])\n",
    "non_sv_removed_y_train = np.concatenate([y_train[:index],y_train[index+1:]])\n",
    "\n",
    "model_non_sv_removed = svm.svm_train(non_sv_removed_y_train, non_sv_removed_x_train, options)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svm.svm_predict(y_test, X_test, main_model)\n",
    "svm.svm_predict(y_test, X_test, model_sv_removed)\n",
    "svm.svm_predict(y_test, X_test, model_non_sv_removed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Main Model:\", len(main_model.get_SV()))\n",
    "print(\"SV removed Model:\", len(model_sv_removed.get_SV()))\n",
    "print(\"Non-SV removed Model:\", len(model_non_sv_removed.get_SV()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# All support vectors of the main model and the model trained with one non-sv data point missing data are exactly the same.\n",
    "main_model.get_SV() == model_non_sv_removed.get_SV()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "main_model_sv_arr = X_train[np.array(main_model.get_sv_indices())-1,:]\n",
    "model_sv_removed_sv_arr = sv_removed_x_train[np.array(model_sv_removed.get_sv_indices())-1,:]\n",
    "model_non_sv_removed_sv_arr = non_sv_removed_x_train[np.array(model_non_sv_removed.get_sv_indices())-1,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "main_model_weights = np.matmul(np.array(main_model.get_sv_coef()).T, main_model_sv_arr)\n",
    "model_sv_removed_weights = np.matmul(np.array(model_sv_removed.get_sv_coef()).T, model_sv_removed_sv_arr)\n",
    "model_non_sv_removed_weights = np.matmul(np.array(model_non_sv_removed.get_sv_coef()).T, model_non_sv_removed_sv_arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(main_model_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(model_sv_removed_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(model_non_sv_removed_weights)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see, when we removed a non-sv data point, hyperplane did not change. On the contrary, removing sv data point changed the hyperplane, as expected."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bonus Task - 10 pts\n",
    "\n",
    "Use Python and [CVXOPT](http://cvxopt.org) QP solver to implement the hard margin SVM. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.7 64-bit",
   "language": "python",
   "name": "python37764bit0f7e80dda11f4f039699ac39dd8cd0ae"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}